{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ErePOC Using Tutorial\n",
    "\n",
    "Test data in this tutorial contains one pair of HEM-binding proteins, and one pair of ADP-binding proteins.  \n",
    "  \n",
    "Data Format:\n",
    "- PDB_ID - Protein's PDB ID\n",
    "- Ligand - Name of pocket's binding ligand\n",
    "- Sequence - Protein's sequence\n",
    "- Pocket Positions - Residue indices of the pocket in the protein sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import esm\n",
    "\n",
    "from model.utils import Net_embed_MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Pockets' ESM-2 Data from Protein Sequences and Pocket Positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDB ID List:  ['101m', '19hc', '8shq', '8igw']\n",
      "Ligand List:  ['HEM', 'HEM', 'ADP', 'ADP']\n"
     ]
    }
   ],
   "source": [
    "# Load example data file\n",
    "file_path = \"./Example-Dataset/4-samples.csv\"\n",
    "sample_data = pd.read_csv(file_path)\n",
    "\n",
    "pdb_id_list = sample_data['PDB_ID'].tolist()              # PDB ID List\n",
    "ligand_list = sample_data['Ligand'].tolist()              # Binding Ligand List\n",
    "sequence_list = sample_data['Sequence'].tolist()          # Protein Sequence List\n",
    "pocket_list = sample_data['Pocket Positions'].tolist()    # Pocket Position List\n",
    "\n",
    "print(\"PDB ID List: \", pdb_id_list)\n",
    "print(\"Ligand List: \", ligand_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load ESM-2 model\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()\n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "model.eval()  # disables dropout for deterministic results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate ESM-2 Representations\n",
    "esm2_representations = []\n",
    "\n",
    "for index, seq in enumerate(sequence_list):\n",
    "    pdb_id = pdb_id_list[index]\n",
    "    int_list = np.asarray([int(num) for num in pocket_list[index].split(',')])\n",
    "\n",
    "    # tuple: (pdb_id, sequence)\n",
    "    tuple_data = (pdb_id, seq)\n",
    "    batch_labels, batch_strs, batch_tokens = batch_converter([tuple_data])\n",
    "    # Extract per-residue representations (on CPU)\n",
    "    with torch.no_grad():\n",
    "        results = model(batch_tokens, repr_layers=[33], return_contacts=True)\n",
    "    token_representations = results[\"representations\"][33]\n",
    "    \n",
    "    # Generate pockets' representations\n",
    "    concatenated_tensor = torch.stack(list(token_representations[0, int_list]), dim=0)\n",
    "    esm2_representations.append(concatenated_tensor.mean(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ESM-2 Data Shape:  torch.Size([4, 1280]) , Pocket's Representation Shape:  torch.Size([1280])\n"
     ]
    }
   ],
   "source": [
    "esm2_representations = torch.from_numpy(np.asarray(esm2_representations))\n",
    "print(\"ESM-2 Data Shape: \", esm2_representations.shape, \", Pocket's Representation Shape: \", esm2_representations[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Pockets' ErePOC Representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2348705/1098898981.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  ErePOC.load_state_dict(torch.load(\"esm2-mlp-best-epoch-275-normAndzerograd.pt\", map_location='cpu'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ErePOC Repr. Array Shape:  torch.Size([4, 256])\n"
     ]
    }
   ],
   "source": [
    "# Load ErePOC Model\n",
    "ErePOC = Net_embed_MLP(input_dim=esm2_representations[0].shape[0],hidden_dim=512,out_dim=256, drop_prob=0.1)\n",
    "# No CUDA Version\n",
    "ErePOC.load_state_dict(torch.load(\"esm2-mlp-best-epoch-275-normAndzerograd.pt\", map_location='cpu'))\n",
    "\n",
    "ErePOC.eval()\n",
    "with torch.no_grad():\n",
    "    # Get ErePOC Repr.\n",
    "    ErePOC_repr_array = ErePOC(esm2_representations)\n",
    "print(\"ErePOC Repr. Array Shape: \", ErePOC_repr_array.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Cosine Similarity of Different Pockets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEM pair similarity:  0.9990303\n",
      "ADP pair similarity:  0.9912592\n",
      "HEM and ADP similarity:  0.07724705\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Cosine Similarity: the HEM pair\n",
    "HEM_pair_sim = cosine_similarity([ErePOC_repr_array[0]], [ErePOC_repr_array[1]])[0][0]\n",
    "# Cosine Similarity: the ADP pair\n",
    "ADP_pair_sim = cosine_similarity([ErePOC_repr_array[2]], [ErePOC_repr_array[3]])[0][0]\n",
    "\n",
    "# Cosine Similairty: HEM and ADP\n",
    "HEM_ADP_sim = cosine_similarity([ErePOC_repr_array[0]], [ErePOC_repr_array[2]])[0][0]\n",
    "\n",
    "print(\"HEM pair similarity: \", HEM_pair_sim)\n",
    "print(\"ADP pair similarity: \", ADP_pair_sim)\n",
    "\n",
    "print(\"HEM and ADP similarity: \", HEM_ADP_sim)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erepoc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
